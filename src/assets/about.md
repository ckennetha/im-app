InterMol is an open-source project with the main goal of understanding the learned molecular representations of chemical language models (cLMs), which further enables us to steer them toward generating new molecules with desirable properties. We trained Sparse Autoencoders (SAEs) on top of [MolFormer](https://github.com/IBM/molformer), a high-performing cLM on the [MoleculeNet](https://moleculenet.org/) benchmark, to uncover its learned chemical features. Then, we developed a browser with an interactive visualizer to make these insights easy to explore.

The project was started by [Christian](javascript:;), [Liam](https://liambai.com), and [Etowah](https://etowahadams.com/) and inspired by [InterProt](https://interprot.com) and [InterPLM](https://interplm.ai), which apply similar interpretability techniques to protein language models (pLMs), particularly ESM-2.